This document contains all the globals, classes, functions and their apis from icebrakes.py.

*EXIT CODES*

    0: Lint passed
    1: Lint failed.


*GLOBALS*

DictStrSet = Dict[str, set]
    DictStrSet is a type aliases because the type hint Dict[str, set] occurs a lot in IceBrakes.


*CLASSES*

States()
This is a bit of a catchall class it handles global state, as well as a way to refresh that state.
    
    *PROPERTIES*

    errors: bool = False
        States.errors is used to track whether the lint failed or passed. And helps with the error codes too.

    indent: int = 0
        Tracks the current indentation level of the file.

    old_indent: int = -999
        The previous indentation level which is needed for changing scopes.

    multiline_status: int = 0
        1: There is an open triple single quote comment.
        0: There are no open multiline comments.
       -1: There is an open triple double quote comment.


    (these are defined in __post_init__())
        names_in_scope: List[Tuple] = [('root', 0)]
            The list tracks the current scope relative to the root of the file and is how we 
            build the custom dict keys that implement scope tracking.

        loops_in_scope: List[Tuple] = [('root', 0)]
            Uses the sample api as names_in_scope to track loops.


    *METHODS*

    update_indent(self, indent: int) -> None
        This method updates the indent level and when the indent level
        goes down it leaves the current scope and loop as needed.


*FUNCTIONS*

dir_or_file(path: str) -> None
    Takes an input string and if it's a dir recursively lints it,
    and if it's a file lints it, and otherwise prints an error message.


icebrakes(filepath: str, dir_mode: bool=False) -> int

    This function takes a python file and lints it. Returns an integer exit code.


get_names_from_file(file: List[str], states: States) -> Tuple[dict, dict] 

    This function parses a python file for any names declared and builds two dictionaries.
    One dict is for all_vars in the file and one dict is only for constants. Constants are 
    defined as vars declared on a line ending in #$. 

    When paren_parse() returns a nonempty string get_names_from_line() adds a new entry to
    States.names_in_scope to keep track of the new namespace we are in.

    Once per line of the file get_names_from_file() also calls States.update_indent() to change
    the current, and past indent vars and to leave the scope when indent decreases.
    
    get_name_from_line(line: str, indent: int) -> str:
        This subfunction is run on nonempty/noncomment lines of the file and actually grabs 
        the names using paren_parse() and equal_sign_parse().

name_gen(name: str, states: States) -> str

    Create unique keys for the all_vars/constants dicts using names_in_scope to create a key.


name_split(name: str) -> str

    Gets all chars to the right of the last period in a string.


loop_parse(line: str, states: States) -> None
    Finds a loop in a given line and updates states. This function
    will need string awareness when that is implemented.


paren_parse(line: str) -> str

    Searches a line for one of these openers ['async def ', 'def' , 'class '] 
    and if an opener is found then the string between the opener and "(" is returned.

    This captures var names on lines like: 
    def name():
    class name():
    async def name():


equal_sign_parse equal_sign_parse(line: str) -> str

    This method parses a string for any single equal sign
    and gets the first name before the equal sign. 
    
    I also added support for other kinds of assignment like +=, *=, /=. The
    dreaded and ugly := operator is not yet supported because it's weird.

    name_assembler(line_to_idx: str='') -> str
        This sub function parses an accepted line for any names assigned with an equal sign.


white_space_parse(file: List[str]) -> int

    Takes a file and calculates how many spaces that file uses to indent by parsing
    the first 100 indented lines of the file.

    We are considering tabs as whitespace but I haven't written the code to calculate how many
    tabs a user is using for one indent. I mostly don't care about tabs to be honest so while
    this will only be a few lines of code, it's not very urgent.

    IceBrakes is not intended to replace your regular linting and if there are major white space
    errors IceBrakes may have unexpected output.


multiline_comment_parse(line: str, states: States) -> int

    This function tracks whether a multiline comment is opened or closed on any given line.
    Using the variable States.multiline_status we track what comment mode IceBrakes is in.
    The possible values for States.multiline_status break down like this.
    
    1: There is an open triple single quote comment.
    0: There are no open multiline comments.
   -1: There is an open triple double quote comment.

    find_first_index(tag: str, line: str) -> Tuple
        Subfunction that grabs the index of the first occurrence of a given string.


cross_reference(constants: DictStrSet, all_vars: DictStrSet, states: States) -> None:

    Once you have the constants and all_vars for a given python file you can cross reference them to see if any constants are overwritten illegally and inform the users. This is the main interface our users will interact with.
